{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from rich import print\n",
    "from onnxruntime import InferenceSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = InferenceSession(\"./weight/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f349ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(\"Hello, how are you?\", return_tensors=\"pt\")\n",
    "print(input_ids)\n",
    "# output = model.run()\n",
    "# print(output)\n",
    "# print(tokenizer.decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run([\"logits\"], {\"input_ids\": input_ids.cpu().numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15025dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input_ids (PyTorch tensor) shape: torch.Size([1, 6])\n",
      "Input_ids (NumPy array) shape for ONNX: (1, 6)\n",
      "ONNX Inference failed: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input_ids for the following indices\n",
      " index: 1 Got: 6 Expected: 1024\n",
      " Please fix either the inputs/outputs or the model.\n",
      "Ensure the model was re-exported with dynamic_axes for 'input_ids'.\n",
      "Verify ONNX model inputs using a tool like Netron or the verification code in the export script.\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import torch  # Assuming your input_ids is initially a PyTorch tensor\n",
    "\n",
    "# --- Your problematic input_ids that caused the error ---\n",
    "# Example: input_ids = torch.tensor([[15496, 11, 703, 389, 345, 30]])\n",
    "# Let's create a dummy one with shape (1, 6) for demonstration\n",
    "input_ids_tensor = torch.randint(0, 50257, (1, 6), dtype=torch.long)  # Shape [1, 6]\n",
    "print(f\"Original input_ids (PyTorch tensor) shape: {input_ids_tensor.shape}\")\n",
    "\n",
    "input_ids_np = input_ids_tensor.cpu().numpy()\n",
    "print(f\"Input_ids (NumPy array) shape for ONNX: {input_ids_np.shape}\")\n",
    "\n",
    "\n",
    "# Load the NEWLY EXPORTED ONNX model\n",
    "onnx_model_path = (\n",
    "    \"./weight/model.onnx\"  # Ensure this is the path to the re-exported model\n",
    ")\n",
    "model = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare input feed (only input_ids)\n",
    "input_feed = {\"input_ids\": input_ids_np}\n",
    "\n",
    "# Run inference\n",
    "# Note: output_names should be a list, e.g., [\"logits\"]\n",
    "try:\n",
    "    outputs = model.run([\"logits\"], input_feed)\n",
    "    print(\"ONNX Inference successful!\")\n",
    "    # The output logits shape should be [batch_size, sequence_length, vocab_size]\n",
    "    # So for input shape [1, 6], output might be [1, 6, 50257]\n",
    "    print(f\"Logits output shape: {outputs[0].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"ONNX Inference failed: {e}\")\n",
    "    print(\"Ensure the model was re-exported with dynamic_axes for 'input_ids'.\")\n",
    "    print(\n",
    "        \"Verify ONNX model inputs using a tool like Netron or the verification code in the export script.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
